{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIa9_d7dkz3h"
   },
   "source": [
    "# Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIYFWKeJmR32",
    "outputId": "bb38122c-cba4-48f7-9107-34adc1a0bec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2023-01-07 15:39:04.534770: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en-core-web-md==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-md==3.4.1) (3.4.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (6.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (57.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.21.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.12.7)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.4.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttX4irFNkt_S",
    "outputId": "1beb5881-e79f-436e-e7f7-42a07947fa16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# Data wrangling\n",
    "import pandas as pd\n",
    "\n",
    "# Word processing\n",
    "import en_core_web_md\n",
    "\n",
    "# Text encoding\n",
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Performing small tasks\n",
    "import functools\n",
    "\n",
    "pd.set_option(\"display.precision\", 12)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xq1PNcbVk6vN"
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"tweets_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ceG__LIGk_yP",
    "outputId": "4e7355a8-8acc-4925-9847-ccf2124d17e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c42f1939-1b99-4ef7-b90d-2eac044ccdea\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Wholesale Markets ablaze</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>We always try to bring the heavy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>: Breaking news:Nigeria flag set ablaze in Aba.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c42f1939-1b99-4ef7-b90d-2eac044ccdea')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c42f1939-1b99-4ef7-b90d-2eac044ccdea button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c42f1939-1b99-4ef7-b90d-2eac044ccdea');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  keyword                                       cleaned_text  target\n",
       "0  ablaze                          Wholesale Markets ablaze        1\n",
       "1  ablaze               We always try to bring the heavy.          0\n",
       "2  ablaze   : Breaking news:Nigeria flag set ablaze in Aba.        1\n",
       "3  ablaze                 Crying out for more! Set me ablaze       0\n",
       "4  ablaze  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yd1TZw7lTcL",
    "outputId": "cf33f8a5-b46a-478d-ba35-65fb41efe2e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7383 entries, 0 to 7382\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   keyword       7383 non-null   object\n",
      " 1   cleaned_text  7383 non-null   object\n",
      " 2   target        7383 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 173.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ii-omGRlffY"
   },
   "source": [
    "## Neural Networks\n",
    "\n",
    "We will train two neural networks in order to predict the target variable. The first one is built from the feature __keyword__, the second is based on the feature __cleaned_text__. \n",
    "\n",
    "\n",
    "### Model based on keyword variable\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wpohHPtqlYLT"
   },
   "outputs": [],
   "source": [
    "nlp_keyword = en_core_web_md.load()\n",
    "corpus_keyword = \" \".join(tweets_df[\"keyword\"].to_list())\n",
    "doc_keyword = nlp_keyword(corpus_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q6VGmXItmKcL"
   },
   "outputs": [],
   "source": [
    "tokens_keyword = [token.text for token in doc_keyword]\n",
    "vocabulary_set_keyword= set(tokens_keyword)\n",
    "vocab_keyword_size = len(vocabulary_set_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AG-8ghHemtu0",
    "outputId": "23826a3d-b66a-4a70-8a23-bff1376b9134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_keyword_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wus7kaKvnFhX",
    "outputId": "f94a3657-cd2a-4941-cbd6-2d0990040b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset: (7383,)\n",
      "Counting the values of the words_in_vocabulary list: True    7383\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# small check to ensure that all the words in the feature keyword are present in vocabulary_set_keyword\n",
    "words_in_vocabulary = []\n",
    "\n",
    "for keyword in tweets_df[\"keyword\"]:\n",
    "  words_in_vocabulary.append(functools.reduce(lambda x, y : x & y, [word in vocabulary_set_keyword for word in keyword.split()]))\n",
    "\n",
    "print(\"Size of the dataset:\", tweets_df[\"keyword\"].shape)\n",
    "print(\"Counting the values of the words_in_vocabulary list:\", pd.Series(words_in_vocabulary).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "H12p4FAppDXU"
   },
   "outputs": [],
   "source": [
    "encoder_keyword = tfds.deprecated.text.TokenTextEncoder(vocabulary_set_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PC53WaXdpPui",
    "outputId": "0e1e3ef3-14fb-477e-da4b-a82dd5a1bc00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_keyword.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "EOKf4tkUp_S4"
   },
   "outputs": [],
   "source": [
    "tf_ds_keyword = tf.data.Dataset.from_tensor_slices((tweets_df[\"keyword\"].values, tweets_df[\"target\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5lSN5YoVqfuB"
   },
   "outputs": [],
   "source": [
    "example_keyword, example_target = next(iter(tf_ds_keyword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmxXDitVqw4_",
    "outputId": "3c30e973-60fb-4923-9482-b0432b021eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  keyword  target\n",
      "0  ablaze       1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(b'ablaze', 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweets_df[[\"keyword\", \"target\"]].head(1))\n",
    "example_keyword.numpy(), example_target.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PZA8gW3yqvpW"
   },
   "outputs": [],
   "source": [
    "def encode_keyword(keyword, target):\n",
    "  encoded_keyword = encoder_keyword.encode(keyword.numpy())\n",
    "  return encoded_keyword, target\n",
    "\n",
    "\n",
    "def encode_keyword_map(keyword, target):\n",
    "  return tf.py_function(encode_keyword, inp=[keyword, target], Tout=(tf.int64, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "m3lZ261OsMjG"
   },
   "outputs": [],
   "source": [
    "all_encoded_keyword = tf_ds_keyword.map(encode_keyword_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ITb-YvLsg6v",
    "outputId": "2036de78-4e8f-4670-9867-1ff9ad7963b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First batch : keyword -> tf.Tensor([1], shape=(1,), dtype=int64) AND target -> tf.Tensor(1, shape=(), dtype=int64)\n",
      "Manual encoding of the first observation : keyword ->  [1] AND target -> 1\n"
     ]
    }
   ],
   "source": [
    "# simple verification of the result of the encoding process\n",
    "for batch_keyword, batch_target in all_encoded_keyword.take(1):\n",
    "  print(\"First batch : keyword ->\", batch_keyword, \"AND target ->\", batch_target)\n",
    "\n",
    "print(\"Manual encoding of the first observation : keyword -> \", encoder_keyword.encode('ablaze'), \"AND target ->\", tweets_df.loc[0, \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RbU6sGyVuGVq"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "TAKE_SIZE = int(0.8*len(tweets_df))\n",
    "\n",
    "train_set_keyword = all_encoded_keyword.take(TAKE_SIZE).shuffle(len(tweets_df))\n",
    "train_set_keyword = train_set_keyword.padded_batch(BATCH_SIZE,  padded_shapes=([-1], []))\n",
    "\n",
    "validation_set_keyword = all_encoded_keyword.skip(TAKE_SIZE)\n",
    "validation_set_keyword = validation_set_keyword.padded_batch(BATCH_SIZE, padded_shapes=([-1], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yh1hYasTvl4Y",
    "outputId": "fd37665e-26b0-4ce8-973d-87ee9262f0fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162 158] <==> ['dust', 'storm']\n",
      "[82  0] <==> ['aftershock', '']\n",
      "[50  0] <==> ['army', '']\n",
      "[139   0] <==> ['quarantined', '']\n",
      "[4 0] <==> ['devastation', '']\n",
      "[15  0] <==> ['lightning', '']\n",
      "[85  0] <==> ['hijacking', '']\n",
      "[124   0] <==> ['mayhem', '']\n",
      "[55  0] <==> ['death', '']\n",
      "[120   0] <==> ['disaster', '']\n",
      "[23  0] <==> ['evacuation', '']\n",
      "[59  0] <==> ['debris', '']\n",
      "[221   0] <==> ['collapse', '']\n",
      "[164   0] <==> ['injury', '']\n",
      "[224   0] <==> ['demolished', '']\n",
      "[164   0] <==> ['injury', '']\n"
     ]
    }
   ],
   "source": [
    "# how does the first batch look like ?\n",
    "# Which words correspond to the given numbers?\n",
    "for batch_keyword, batch_target in train_set_keyword.take(1):\n",
    "  for i in range(len(batch_keyword)):\n",
    "    print(batch_keyword[i, :].numpy(), \"<==>\", [encoder_keyword.decode([number]) for number in batch_keyword[i, :].numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1a2LdSJyH7f"
   },
   "source": [
    "#### Modeling\n",
    "\n",
    "The architecture of the neural network is defined: the type of layer, the number of neurons in each layer, the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PUjSkJ9eyKAw"
   },
   "outputs": [],
   "source": [
    "model_keyword = tf.keras.Sequential([       \n",
    "                  tf.keras.layers.Embedding(vocab_keyword_size + 1, 16),\n",
    "                  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)),\n",
    "                  # tf.keras.layers.Conv1D(16, 3, activation=\"relu\"),\n",
    "                  # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "                  tf.keras.layers.LSTM(8, return_sequences=False),               \n",
    "                  # tf.keras.layers.Dense(64, activation='relu'),\n",
    "                  # tf.keras.layers.Dense(32, activation='relu'),\n",
    "                  tf.keras.layers.Dense(16, activation='relu'),\n",
    "                  tf.keras.layers.Dense(8, activation='relu'),\n",
    "                  tf.keras.layers.Dense(1, activation=\"sigmoid\")              \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVrr4lUV1-xF",
    "outputId": "4bc4dab3-6747-4b5b-c874-345d96ea860c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          3680      \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 32)         4224      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 8)                 1312      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                144       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,505\n",
      "Trainable params: 9,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keyword.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No71ds-330-k"
   },
   "source": [
    "We define the parameters of the training process : the cost function, the evaluation metrics, the optimisation algorithm, the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-a9xrTsR2Dqp"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=2500,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    "    )\n",
    "\n",
    "model_keyword.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    metrics=[tf.keras.metrics.binary_accuracy]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mvyu4brq86tx",
    "outputId": "01e1e804-1fe4-43b0-cdba-0823b81fcc05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "370/370 [==============================] - 14s 17ms/step - loss: 0.6299 - binary_accuracy: 0.6453 - val_loss: 0.7054 - val_binary_accuracy: 0.4414\n",
      "Epoch 2/20\n",
      "370/370 [==============================] - 7s 13ms/step - loss: 0.5484 - binary_accuracy: 0.7282 - val_loss: 0.6843 - val_binary_accuracy: 0.5173\n",
      "Epoch 3/20\n",
      "370/370 [==============================] - 7s 13ms/step - loss: 0.5406 - binary_accuracy: 0.7294 - val_loss: 0.6818 - val_binary_accuracy: 0.5213\n",
      "Epoch 4/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5361 - binary_accuracy: 0.7318 - val_loss: 0.6747 - val_binary_accuracy: 0.5829\n",
      "Epoch 5/20\n",
      "370/370 [==============================] - 7s 13ms/step - loss: 0.5337 - binary_accuracy: 0.7328 - val_loss: 0.6745 - val_binary_accuracy: 0.5856\n",
      "Epoch 6/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5317 - binary_accuracy: 0.7345 - val_loss: 0.6731 - val_binary_accuracy: 0.5924\n",
      "Epoch 7/20\n",
      "370/370 [==============================] - 7s 13ms/step - loss: 0.5302 - binary_accuracy: 0.7326 - val_loss: 0.6698 - val_binary_accuracy: 0.6066\n",
      "Epoch 8/20\n",
      "370/370 [==============================] - 7s 13ms/step - loss: 0.5303 - binary_accuracy: 0.7337 - val_loss: 0.6719 - val_binary_accuracy: 0.5985\n",
      "Epoch 9/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5296 - binary_accuracy: 0.7340 - val_loss: 0.6710 - val_binary_accuracy: 0.6066\n",
      "Epoch 10/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5294 - binary_accuracy: 0.7335 - val_loss: 0.6708 - val_binary_accuracy: 0.6066\n",
      "Epoch 11/20\n",
      "370/370 [==============================] - 6s 12ms/step - loss: 0.5288 - binary_accuracy: 0.7338 - val_loss: 0.6723 - val_binary_accuracy: 0.6066\n",
      "Epoch 12/20\n",
      "370/370 [==============================] - 6s 12ms/step - loss: 0.5284 - binary_accuracy: 0.7354 - val_loss: 0.6715 - val_binary_accuracy: 0.5992\n",
      "Epoch 13/20\n",
      "370/370 [==============================] - 7s 14ms/step - loss: 0.5283 - binary_accuracy: 0.7350 - val_loss: 0.6721 - val_binary_accuracy: 0.5992\n",
      "Epoch 14/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5284 - binary_accuracy: 0.7355 - val_loss: 0.6729 - val_binary_accuracy: 0.6066\n",
      "Epoch 15/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5275 - binary_accuracy: 0.7355 - val_loss: 0.6713 - val_binary_accuracy: 0.6066\n",
      "Epoch 16/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5272 - binary_accuracy: 0.7359 - val_loss: 0.6703 - val_binary_accuracy: 0.5992\n",
      "Epoch 17/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5272 - binary_accuracy: 0.7355 - val_loss: 0.6719 - val_binary_accuracy: 0.6066\n",
      "Epoch 18/20\n",
      "370/370 [==============================] - 6s 13ms/step - loss: 0.5264 - binary_accuracy: 0.7386 - val_loss: 0.6735 - val_binary_accuracy: 0.6019\n",
      "Epoch 19/20\n",
      "370/370 [==============================] - 6s 12ms/step - loss: 0.5272 - binary_accuracy: 0.7337 - val_loss: 0.6719 - val_binary_accuracy: 0.6066\n",
      "Epoch 20/20\n",
      "370/370 [==============================] - 6s 12ms/step - loss: 0.5266 - binary_accuracy: 0.7367 - val_loss: 0.6700 - val_binary_accuracy: 0.5992\n"
     ]
    }
   ],
   "source": [
    "history = model_keyword.fit(train_set_keyword, epochs=20, validation_data=validation_set_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "ctnfPR9riemI",
    "outputId": "8a874df4-7450-4041-847a-d135dc8c9911"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ee2ae968-a0ce-4904-863e-984516462f30\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.629905998707</td>\n",
       "      <td>0.645276010036</td>\n",
       "      <td>0.705410838127</td>\n",
       "      <td>0.441435337067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.548413693905</td>\n",
       "      <td>0.728242456913</td>\n",
       "      <td>0.684342265129</td>\n",
       "      <td>0.517264723778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540649950504</td>\n",
       "      <td>0.729427695274</td>\n",
       "      <td>0.681768178940</td>\n",
       "      <td>0.521327018738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.536063671112</td>\n",
       "      <td>0.731798171997</td>\n",
       "      <td>0.674696505070</td>\n",
       "      <td>0.582938373089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.533747255802</td>\n",
       "      <td>0.732814073563</td>\n",
       "      <td>0.674517273903</td>\n",
       "      <td>0.585646569729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.531697392464</td>\n",
       "      <td>0.734507262707</td>\n",
       "      <td>0.673090219498</td>\n",
       "      <td>0.592417061329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.530204057693</td>\n",
       "      <td>0.732644796371</td>\n",
       "      <td>0.669837176800</td>\n",
       "      <td>0.606635093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.530308485031</td>\n",
       "      <td>0.733660697937</td>\n",
       "      <td>0.671934902668</td>\n",
       "      <td>0.598510503769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.529610753059</td>\n",
       "      <td>0.733999311924</td>\n",
       "      <td>0.671041131020</td>\n",
       "      <td>0.606635093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.529380023479</td>\n",
       "      <td>0.733491361141</td>\n",
       "      <td>0.670776605606</td>\n",
       "      <td>0.606635093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.528769671917</td>\n",
       "      <td>0.733829975128</td>\n",
       "      <td>0.672320246696</td>\n",
       "      <td>0.606635093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.528403818607</td>\n",
       "      <td>0.735353887081</td>\n",
       "      <td>0.671538829803</td>\n",
       "      <td>0.599187552929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.528329432011</td>\n",
       "      <td>0.735015213490</td>\n",
       "      <td>0.672125160694</td>\n",
       "      <td>0.599187552929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.528433680534</td>\n",
       "      <td>0.735523223877</td>\n",
       "      <td>0.672910392284</td>\n",
       "      <td>0.606635093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.527470469475</td>\n",
       "      <td>0.735523223877</td>\n",
       "      <td>0.671339690685</td>\n",
       "      <td>0.606635093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.527168333530</td>\n",
       "      <td>0.735861837864</td>\n",
       "      <td>0.670341372490</td>\n",
       "      <td>0.599187552929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.527222752571</td>\n",
       "      <td>0.735523223877</td>\n",
       "      <td>0.671860933304</td>\n",
       "      <td>0.606635093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.526431381702</td>\n",
       "      <td>0.738570928574</td>\n",
       "      <td>0.673535704613</td>\n",
       "      <td>0.601895749569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.527196943760</td>\n",
       "      <td>0.733660697937</td>\n",
       "      <td>0.671891570091</td>\n",
       "      <td>0.606635093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.526558339596</td>\n",
       "      <td>0.736708402634</td>\n",
       "      <td>0.670035600662</td>\n",
       "      <td>0.599187552929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee2ae968-a0ce-4904-863e-984516462f30')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ee2ae968-a0ce-4904-863e-984516462f30 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ee2ae968-a0ce-4904-863e-984516462f30');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              loss  binary_accuracy        val_loss  val_binary_accuracy\n",
       "0   0.629905998707   0.645276010036  0.705410838127       0.441435337067\n",
       "1   0.548413693905   0.728242456913  0.684342265129       0.517264723778\n",
       "2   0.540649950504   0.729427695274  0.681768178940       0.521327018738\n",
       "3   0.536063671112   0.731798171997  0.674696505070       0.582938373089\n",
       "4   0.533747255802   0.732814073563  0.674517273903       0.585646569729\n",
       "5   0.531697392464   0.734507262707  0.673090219498       0.592417061329\n",
       "6   0.530204057693   0.732644796371  0.669837176800       0.606635093689\n",
       "7   0.530308485031   0.733660697937  0.671934902668       0.598510503769\n",
       "8   0.529610753059   0.733999311924  0.671041131020       0.606635093689\n",
       "9   0.529380023479   0.733491361141  0.670776605606       0.606635093689\n",
       "10  0.528769671917   0.733829975128  0.672320246696       0.606635093689\n",
       "11  0.528403818607   0.735353887081  0.671538829803       0.599187552929\n",
       "12  0.528329432011   0.735015213490  0.672125160694       0.599187552929\n",
       "13  0.528433680534   0.735523223877  0.672910392284       0.606635093689\n",
       "14  0.527470469475   0.735523223877  0.671339690685       0.606635093689\n",
       "15  0.527168333530   0.735861837864  0.670341372490       0.599187552929\n",
       "16  0.527222752571   0.735523223877  0.671860933304       0.606635093689\n",
       "17  0.526431381702   0.738570928574  0.673535704613       0.601895749569\n",
       "18  0.527196943760   0.733660697937  0.671891570091       0.606635093689\n",
       "19  0.526558339596   0.736708402634  0.670035600662       0.599187552929"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMmBmKc3NVoT"
   },
   "source": [
    "* This model is clearly overfitted: there is a 20% gap between the score metrics of the two data sets (training and validation) and a 25% gap between the last values of the cost functions. \n",
    "* We see that there is almost no evolution of the cost function and the score metric from the fifth epoch onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RD-iJCKuVCsn"
   },
   "source": [
    "### Model based on cleaned_text variable\n",
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "WLa9KACnVh45"
   },
   "outputs": [],
   "source": [
    "nlp_text = en_core_web_md.load()\n",
    "corpus_text = \" \".join(tweets_df[\"cleaned_text\"].to_list())\n",
    "doc_text = nlp_text(corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wsU_918yVUjg"
   },
   "outputs": [],
   "source": [
    "tokens_text = [token.text for token in doc_text]\n",
    "vocabulary_set_text= set(tokens_text)\n",
    "vocab_text_size = len(vocabulary_set_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__BB4WvWVdKE",
    "outputId": "2dc460e9-c6c5-4165-b218-12e40b84a2d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17937"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_text_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oGzRlPWRV_a3"
   },
   "outputs": [],
   "source": [
    "encoder_text = tfds.deprecated.text.TokenTextEncoder(vocabulary_set_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9eYBbCEWHYC",
    "outputId": "308ab52c-f0f4-44d2-e08b-fd51f37f8ee7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17939"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_text.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Ez7EeX_RWPRv"
   },
   "outputs": [],
   "source": [
    "tf_ds_text = tf.data.Dataset.from_tensor_slices((tweets_df[\"cleaned_text\"].values, tweets_df[\"target\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jx9h9DDMWTGk"
   },
   "outputs": [],
   "source": [
    "example_text, example_target = next(iter(tf_ds_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckRr5esQWmDQ",
    "outputId": "9869d003-5a68-46d8-f14e-988a17ef2967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 cleaned_text  target\n",
      "0   Wholesale Markets ablaze        1\n",
      "b' Wholesale Markets ablaze ' 1\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df[[\"cleaned_text\", \"target\"]].head(1))\n",
    "print(example_text.numpy(), example_target.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEyYh_ClW5PV",
    "outputId": "b78c016a-5997-43c0-b09b-85e45b87db47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial text : b' Wholesale Markets ablaze ' => Encoding :  [5060, 15405, 3655]\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial text :\", example_text.numpy(),\"=> Encoding : \", encoder_text.encode(example_text.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "uYZXF_-rX8aq"
   },
   "outputs": [],
   "source": [
    "def encode_text(text, target):\n",
    "  encoded_text = encoder_text.encode(text.numpy())\n",
    "  return encoded_text, target\n",
    "\n",
    "\n",
    "def encode_text_map(text, target):\n",
    "  return tf.py_function(encode_text, inp=[text, target], Tout=(tf.int64, tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "_sG6uj_eYHsU"
   },
   "outputs": [],
   "source": [
    "all_encoded_text = tf_ds_text.map(encode_text_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3koAjNvuYJ1n"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "TAKE_SIZE = int(0.8*len(tweets_df))\n",
    "\n",
    "train_set_text = all_encoded_text.take(TAKE_SIZE).shuffle(len(tweets_df))\n",
    "train_set_text = train_set_text.padded_batch(BATCH_SIZE,  padded_shapes=([-1], []))\n",
    "\n",
    "validation_set_text = all_encoded_text.skip(TAKE_SIZE)\n",
    "validation_set_text = validation_set_text.padded_batch(BATCH_SIZE, padded_shapes=([-1], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QRZqifaxY2FR",
    "outputId": "3e32eed6-88e2-4e75-ea38-59153b426202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first batch (16, 22)\n",
      "[ 2336  9703 14793 16849  5985 16957 15981    52  7635  8236 16765 17598\n",
      " 14342 16359  2349  9703 14319 13109 13885 13534     0     0]\n",
      "[ 5361  6456 11980 14868  4356  2666 11653 15981 13495  4516     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "[  285  2641 11157 14498  6399 14642 17503  5682 14804  6399 13212  4793\n",
      " 11157 11688 11590  4357 12663     0     0     0     0     0]\n",
      "[11157  1285  5770  2211 11785 17866     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "[12725   896  9703  8819  8700  4320  3081  8700  9773  6681 16765 14182\n",
      " 13376 11221 14989     0     0     0     0     0     0     0]\n",
      "[ 8995  5998  1438 17639 14197  3835 17245 15685 10156  9723 14197  6341\n",
      " 15834  5210  8324  5998  3595 11968 15869     0     0     0]\n",
      "[ 1083 11157 14584  5503 15092  6715  9288  8700   930   217  5583   556\n",
      "  3457  9878  7477  1528 12868  1668 16066 10490 17654 14642]\n",
      "[ 4203 14642   795 11733  4163  7390     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "[ 4571 10756 10589  3836 13854 14710  7811  6715 10733 13854 14976  8351\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "[15184 11607 10558   146  3020  1551  3569  8304  7678  2783   667  2022\n",
      " 15995 17157 15959     0     0     0     0     0     0     0]\n",
      "[14440 17746  3457 16879 11415   690 17890 15835 15137  6892 11940     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "[12579 17938 16191  3155  9898   783  6797  2806 16884 14435 15137  2910\n",
      " 15037 14804  2322  2073   647 12731 17938 16191     0     0]\n",
      "[ 3888  4131 12663 11285 12523   791  9128     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "[  489 16457 10774 16178 14283  6009  2789 16537 15981  4321     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "[15557 11351  9633 17654   167  9703  2666 15379 14804 15130 10686  9703\n",
      " 15188  9703 13200     0     0     0     0     0     0     0]\n",
      "[ 7962 11441  1285 12173  2666 13570  9703 10722 11655 15613  6009 13310\n",
      "     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# just a look at the first batch\n",
    "for batch_text, batch_target in train_set_text.take(1):\n",
    "  print(\"Shape of the first batch\", batch_text.shape)\n",
    "  for i in range(len(batch_text)):\n",
    "    print(batch_text[i, :].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAnW2WUYZyMI"
   },
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "MTDRGrzfZm0r"
   },
   "outputs": [],
   "source": [
    "model_text = tf.keras.Sequential([\n",
    "                  tf.keras.layers.Embedding(encoder_text.vocab_size, 16),\n",
    "                  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)),\n",
    "                  # tf.keras.layers.Conv1D(4, 3, activation=\"relu\"),\n",
    "                  # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences=True)),\n",
    "                  tf.keras.layers.LSTM(8, return_sequences=False),               \n",
    "                  # tf.keras.layers.Dense(16, activation='relu'),\n",
    "                  # tf.keras.layers.Dense(8, activation='relu'),\n",
    "                  tf.keras.layers.Dense(4, activation='relu'),\n",
    "                  tf.keras.layers.Dense(2, activation='relu'),\n",
    "                  tf.keras.layers.Dense(1, activation=\"sigmoid\")              \n",
    "                  ],\n",
    "                   name=\"model_text\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pv_V76d6aCw0",
    "outputId": "09de88a3-3d5f-4817-881d-19ebafa53111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_text\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 16)          287024    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, None, 32)         4224      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 8)                 1312      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 292,609\n",
      "Trainable params: 292,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_text.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXKE8e3HaGCR",
    "outputId": "2475f404-ed3c-4ad4-8bed-a95e10217eec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of observations used for training at each epoch\n",
    "int(TAKE_SIZE/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HilzL6tYbRmR",
    "outputId": "ac1e0aa7-5d7c-4b97-c693-9e64901c0f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7VZ00jgbbtE",
    "outputId": "d1060f0d-953b-4f02-8468-d04fe6e8045c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'initial_learning_rate': 0.001,\n",
       " 'decay_steps': 2500,\n",
       " 'decay_rate': 0.96,\n",
       " 'staircase': True,\n",
       " 'name': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_schedule.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dwaw3LJfckxH",
    "outputId": "4d053338-4ac9-429b-cc11-afdb3d33b8b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model_text',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, None),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'embedding_1_input'}},\n",
       "  {'class_name': 'Embedding',\n",
       "   'config': {'name': 'embedding_1',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, None),\n",
       "    'dtype': 'float32',\n",
       "    'input_dim': 17939,\n",
       "    'output_dim': 16,\n",
       "    'embeddings_initializer': {'class_name': 'RandomUniform',\n",
       "     'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}},\n",
       "    'embeddings_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'embeddings_constraint': None,\n",
       "    'mask_zero': False,\n",
       "    'input_length': None}},\n",
       "  {'class_name': 'Bidirectional',\n",
       "   'config': {'name': 'bidirectional_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'layer': {'class_name': 'LSTM',\n",
       "     'config': {'name': 'lstm_2',\n",
       "      'trainable': True,\n",
       "      'dtype': 'float32',\n",
       "      'return_sequences': True,\n",
       "      'return_state': False,\n",
       "      'go_backwards': False,\n",
       "      'stateful': False,\n",
       "      'unroll': False,\n",
       "      'time_major': False,\n",
       "      'units': 16,\n",
       "      'activation': 'tanh',\n",
       "      'recurrent_activation': 'sigmoid',\n",
       "      'use_bias': True,\n",
       "      'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "       'config': {'seed': None}},\n",
       "      'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "       'config': {'gain': 1.0, 'seed': None}},\n",
       "      'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "      'unit_forget_bias': True,\n",
       "      'kernel_regularizer': None,\n",
       "      'recurrent_regularizer': None,\n",
       "      'bias_regularizer': None,\n",
       "      'activity_regularizer': None,\n",
       "      'kernel_constraint': None,\n",
       "      'recurrent_constraint': None,\n",
       "      'bias_constraint': None,\n",
       "      'dropout': 0.0,\n",
       "      'recurrent_dropout': 0.0,\n",
       "      'implementation': 2}},\n",
       "    'merge_mode': 'concat'}},\n",
       "  {'class_name': 'LSTM',\n",
       "   'config': {'name': 'lstm_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': False,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': False,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'units': 8,\n",
       "    'activation': 'tanh',\n",
       "    'recurrent_activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'recurrent_initializer': {'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.0,\n",
       "    'recurrent_dropout': 0.0,\n",
       "    'implementation': 2}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 4,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_4',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 2,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_5',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_text.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Gs8Fcd3waZzy"
   },
   "outputs": [],
   "source": [
    "model_text.compile(\n",
    "          optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "          loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "          metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPDNByNMb7ZY",
    "outputId": "d4af8276-0d12-45c7-d42e-3f0be06a6533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "370/370 [==============================] - 27s 48ms/step - loss: 0.6438 - binary_accuracy: 0.5969 - val_loss: 0.6276 - val_binary_accuracy: 0.6757\n",
      "Epoch 2/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.5205 - binary_accuracy: 0.8143 - val_loss: 0.6050 - val_binary_accuracy: 0.7495\n",
      "Epoch 3/20\n",
      "370/370 [==============================] - 19s 42ms/step - loss: 0.4178 - binary_accuracy: 0.8728 - val_loss: 0.5777 - val_binary_accuracy: 0.7251\n",
      "Epoch 4/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.3387 - binary_accuracy: 0.9006 - val_loss: 0.6304 - val_binary_accuracy: 0.7251\n",
      "Epoch 5/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.2766 - binary_accuracy: 0.9245 - val_loss: 0.6871 - val_binary_accuracy: 0.6378\n",
      "Epoch 6/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.2367 - binary_accuracy: 0.9396 - val_loss: 0.6530 - val_binary_accuracy: 0.6987\n",
      "Epoch 7/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.2172 - binary_accuracy: 0.9443 - val_loss: 0.7712 - val_binary_accuracy: 0.6845\n",
      "Epoch 8/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1956 - binary_accuracy: 0.9485 - val_loss: 0.7499 - val_binary_accuracy: 0.6892\n",
      "Epoch 9/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1826 - binary_accuracy: 0.9511 - val_loss: 0.7529 - val_binary_accuracy: 0.6960\n",
      "Epoch 10/20\n",
      "370/370 [==============================] - 19s 42ms/step - loss: 0.1728 - binary_accuracy: 0.9533 - val_loss: 0.7938 - val_binary_accuracy: 0.6960\n",
      "Epoch 11/20\n",
      "370/370 [==============================] - 19s 42ms/step - loss: 0.1686 - binary_accuracy: 0.9534 - val_loss: 0.8287 - val_binary_accuracy: 0.6865\n",
      "Epoch 12/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1686 - binary_accuracy: 0.9517 - val_loss: 0.8201 - val_binary_accuracy: 0.6838\n",
      "Epoch 13/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1559 - binary_accuracy: 0.9565 - val_loss: 0.7806 - val_binary_accuracy: 0.6737\n",
      "Epoch 14/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1481 - binary_accuracy: 0.9595 - val_loss: 0.8158 - val_binary_accuracy: 0.6913\n",
      "Epoch 15/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1352 - binary_accuracy: 0.9636 - val_loss: 0.7220 - val_binary_accuracy: 0.7312\n",
      "Epoch 16/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1306 - binary_accuracy: 0.9621 - val_loss: 0.8148 - val_binary_accuracy: 0.6926\n",
      "Epoch 17/20\n",
      "370/370 [==============================] - 20s 44ms/step - loss: 0.1208 - binary_accuracy: 0.9672 - val_loss: 0.8648 - val_binary_accuracy: 0.7095\n",
      "Epoch 18/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1107 - binary_accuracy: 0.9694 - val_loss: 0.9594 - val_binary_accuracy: 0.7183\n",
      "Epoch 19/20\n",
      "370/370 [==============================] - 19s 43ms/step - loss: 0.1116 - binary_accuracy: 0.9692 - val_loss: 0.9978 - val_binary_accuracy: 0.6947\n",
      "Epoch 20/20\n",
      "370/370 [==============================] - 19s 42ms/step - loss: 0.1098 - binary_accuracy: 0.9685 - val_loss: 0.9746 - val_binary_accuracy: 0.6892\n"
     ]
    }
   ],
   "source": [
    "history_text = model_text.fit(train_set_text, epochs=20, validation_data=validation_set_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "_toCRi2Zc2lR",
    "outputId": "f6e4c3aa-fb43-4c25-82fc-9a3a899f44a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-976430a7-8c4e-43f9-a99f-53b75e1931ee\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643795073032</td>\n",
       "      <td>0.596850633621</td>\n",
       "      <td>0.627597093582</td>\n",
       "      <td>0.675693988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.520545601845</td>\n",
       "      <td>0.814256668091</td>\n",
       "      <td>0.605036377907</td>\n",
       "      <td>0.749492228031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.417762845755</td>\n",
       "      <td>0.872841179371</td>\n",
       "      <td>0.577682971954</td>\n",
       "      <td>0.725118458271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.338662117720</td>\n",
       "      <td>0.900609552860</td>\n",
       "      <td>0.630423963070</td>\n",
       "      <td>0.725118458271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276577919722</td>\n",
       "      <td>0.924483597279</td>\n",
       "      <td>0.687071263790</td>\n",
       "      <td>0.637779295444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.236672505736</td>\n",
       "      <td>0.939553022385</td>\n",
       "      <td>0.652973175049</td>\n",
       "      <td>0.698713600636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.217244133353</td>\n",
       "      <td>0.944293916225</td>\n",
       "      <td>0.771159410477</td>\n",
       "      <td>0.684495627880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.195550709963</td>\n",
       "      <td>0.948526918888</td>\n",
       "      <td>0.749903440475</td>\n",
       "      <td>0.689234912395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.182583555579</td>\n",
       "      <td>0.951066732407</td>\n",
       "      <td>0.752912580967</td>\n",
       "      <td>0.696005403996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.172840684652</td>\n",
       "      <td>0.953267872334</td>\n",
       "      <td>0.793782889843</td>\n",
       "      <td>0.696005403996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.168623581529</td>\n",
       "      <td>0.953437209129</td>\n",
       "      <td>0.828669011593</td>\n",
       "      <td>0.686526715755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.168578699231</td>\n",
       "      <td>0.951743960381</td>\n",
       "      <td>0.820145130157</td>\n",
       "      <td>0.683818578720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.155852168798</td>\n",
       "      <td>0.956484913826</td>\n",
       "      <td>0.780638933182</td>\n",
       "      <td>0.673662841320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.148073077202</td>\n",
       "      <td>0.959532678127</td>\n",
       "      <td>0.815821588039</td>\n",
       "      <td>0.691266059875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.135246232152</td>\n",
       "      <td>0.963596343994</td>\n",
       "      <td>0.721986651421</td>\n",
       "      <td>0.731211900711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.130632072687</td>\n",
       "      <td>0.962072491646</td>\n",
       "      <td>0.814772307873</td>\n",
       "      <td>0.692620158195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.120807774365</td>\n",
       "      <td>0.967152059078</td>\n",
       "      <td>0.864845931530</td>\n",
       "      <td>0.709546387196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.110722921789</td>\n",
       "      <td>0.969353199005</td>\n",
       "      <td>0.959442138672</td>\n",
       "      <td>0.718348026276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.111623130739</td>\n",
       "      <td>0.969183862209</td>\n",
       "      <td>0.997782230377</td>\n",
       "      <td>0.694651305676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.109806589782</td>\n",
       "      <td>0.968506574631</td>\n",
       "      <td>0.974571108818</td>\n",
       "      <td>0.689234912395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-976430a7-8c4e-43f9-a99f-53b75e1931ee')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-976430a7-8c4e-43f9-a99f-53b75e1931ee button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-976430a7-8c4e-43f9-a99f-53b75e1931ee');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              loss  binary_accuracy        val_loss  val_binary_accuracy\n",
       "0   0.643795073032   0.596850633621  0.627597093582       0.675693988800\n",
       "1   0.520545601845   0.814256668091  0.605036377907       0.749492228031\n",
       "2   0.417762845755   0.872841179371  0.577682971954       0.725118458271\n",
       "3   0.338662117720   0.900609552860  0.630423963070       0.725118458271\n",
       "4   0.276577919722   0.924483597279  0.687071263790       0.637779295444\n",
       "5   0.236672505736   0.939553022385  0.652973175049       0.698713600636\n",
       "6   0.217244133353   0.944293916225  0.771159410477       0.684495627880\n",
       "7   0.195550709963   0.948526918888  0.749903440475       0.689234912395\n",
       "8   0.182583555579   0.951066732407  0.752912580967       0.696005403996\n",
       "9   0.172840684652   0.953267872334  0.793782889843       0.696005403996\n",
       "10  0.168623581529   0.953437209129  0.828669011593       0.686526715755\n",
       "11  0.168578699231   0.951743960381  0.820145130157       0.683818578720\n",
       "12  0.155852168798   0.956484913826  0.780638933182       0.673662841320\n",
       "13  0.148073077202   0.959532678127  0.815821588039       0.691266059875\n",
       "14  0.135246232152   0.963596343994  0.721986651421       0.731211900711\n",
       "15  0.130632072687   0.962072491646  0.814772307873       0.692620158195\n",
       "16  0.120807774365   0.967152059078  0.864845931530       0.709546387196\n",
       "17  0.110722921789   0.969353199005  0.959442138672       0.718348026276\n",
       "18  0.111623130739   0.969183862209  0.997782230377       0.694651305676\n",
       "19  0.109806589782   0.968506574631  0.974571108818       0.689234912395"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history_text.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59QsAGAtkLt7"
   },
   "source": [
    "* This model is highly overfitted : there is an almost 30% change between the score metrics of the two data sets.\n",
    "* On the training set, the cost function continuously decreases from 0.6437 to 0.1098, while on the validation set, the cost function alternates between increasing and decreasing throughout the training process.\n",
    "* In the third epoch, focusing on the validation set, the cost function reaches its absolute minimum on validation set : if we decide to consider the model at this stage, we obtain a model with an accuracy of 87.28% on the training set and a score of 72.51% on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djamOg3slXhy"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "* The results of the study are inconclusive. Getting a machine to \"read\" a tweet indicating that a natural disaster has occurred is not easy. \n",
    "* In Data Understranding and Data Preparation phase, we saw that the keywords of tweets relating a real disaster were more precise and descriptive. One way of solving this problem would be to develop bags of words via factorial analysis algorithms to have a better vision of the keywords associated with real natural disasters and those associated with fake ones.\n",
    "* A second way concerns the cleaning phase of the text contained in the tweets: it is possible that we missed certain formatting errors, which could then have disrupted the predictive capacities of our models. \n",
    "* The last way to solve the disaster prediction problem would be to modify the architecture of the neural networks presented in this study. We used the same architecture for both models, but in fact we tested several architectures in order to obtain better scores. In the time available, it is obviously impossible to train all possible architectures. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
